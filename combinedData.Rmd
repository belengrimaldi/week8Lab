---
title: "Word Sentiment Analysis for Data Science"
author: "Belen, Kay, and Amanda"
date: "3/30/2021"
output:
  html_document:
    toc: TRUE
    theme: journal
    toc_float: TRUE
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE, message=FALSE}
install.packages("dplyr")
library(dplyr)
install.packages("DT")
library(DT)
library(tidyverse)
library(tidytext)
library(ggwordcloud)
library(textdata)
install.packages("textreadr")
library("textreadr")
install.packages("striprtf")
library(striprtf)
save.image("tidytext.RData")

```

```{r, echo=FALSE, message=FALSE}
grep_clean <- function(data, column, listOfStrings) {
  for (str in listOfStrings) {
    data <- data[!grepl(str, column),]
  }
}
```


## Regional Articles Sentiment Analysis {.tabset}
### Northeast (NY) {.tabset}
```{r, echo=FALSE, message=FALSE, results=FALSE}
# Chunk to clean data

# Read in the articles from the .txt file
ny <- read_lines("ny.txt")

# Clean the data and make it usable
ny <- tibble(ny)

# Cut out the lines that contain TOC
ny <- tail(ny, -1098)

# Cut out any rows containing the following words, which indicate that those rows are not a part of any of the articles

grep_list <- list("Length", "Highlight", "Copyright", "Load-Date", "Section", "Byline", "PM EDT", "PM EST", "AM EST", "Graphic", "www")

for (str in grep_list) {
  ny <- ny[!grepl(str, ny$ny),]
}

exact_list <- list("", " ", "Body", "Link to Image", "End of Document", "Page of ")

for (str in exact_list) {
  ny <- ny[!(ny$ny==str),]
}


ny$ny <- as.character(ny$ny)

# Save the cleaned data for a tf-idf analysis later
clean_ny <- ny

```


```{r, echo=FALSE, message=FALSE}
# Create a new data frame with count of individual words
ny <- ny %>%
  unnest_tokens(word, ny)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)


# Do sentiment analyses for the NE region

ny_afinn <- ny %>%
  inner_join(get_sentiments("afinn"))

ny_nrc <- ny %>%
  inner_join(get_sentiments("nrc"))

ny_bing <- ny %>%
  inner_join(get_sentiments("bing"))
```

#### AFINN
```{r, echo=FALSE, message=FALSE}
# Plot the results
ggplot(data = ny_afinn, 
       aes(x=value)) +
  geom_histogram() +
  ggtitle("Northeast Sentiment Range") +
  theme_minimal()
```

#### NRC
```{r, echo=FALSE, message=FALSE}
# Plot the results
ggplot(ny_nrc, 
    aes(x = sentiment)) + 
    ggtitle("Northeast Sentiment Range") +
    geom_bar() +
    theme_minimal()
```

#### Bing
```{r, echo=FALSE, message=FALSE}
# Plot the results
ggplot(ny_bing, 
    aes(x = sentiment, fill=sentiment)) + 
    ggtitle("Northeast Sentiment Range") +
    geom_bar() +
    theme_minimal() +
    labs(x = 'Sentiment', y = 'Count') +
    scale_color_manual(values = c('red', 'green'))

```


### West Coast (CA & OR) {.tabset}
```{r, echo=FALSE, message=FALSE, results=FALSE}
# Chunk for cleaning data

west <- read_lines("west.txt")
west <- tibble(west)

# Cut out the lines that contain TOC
west <- tail(west, -800)

# Cut out any rows containing the following words, which indicate that those rows are not a part of any of the articles

grep_list <- list("Length", "Highlight", "Copyright", "Load-Date", "Section", "Byline", "PM PST", "AM PST", "Graphic", "www")

for (str in grep_list) {
  west <- west[!grepl(str, west$west),]
}

exact_list <- list("", " ", "Body", "Link to Image", "End of Document", "Page of ", "Final Edition")

for (str in exact_list) {
  west <- west[!(west$west==str),]
}

west$west <- as.character(west$west)

# Save the cleaned data for later use
clean_west <- west
```

```{r, echo=FALSE, message=FALSE}
west <- west %>%
  unnest_tokens(word, west)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)

# Sentiment analysis for West Coast

west_afinn <- west %>%
  inner_join(get_sentiments("afinn"))

west_nrc <- west %>%
  inner_join(get_sentiments("nrc"))

west_bing <- west %>%
  inner_join(get_sentiments("bing"))
```

#### AFINN
```{r, echo=FALSE, message=FALSE}
# Plot the results
ggplot(data = west_afinn, 
       aes(x=value)) +
  geom_histogram() +
  ggtitle("West Coast Sentiment Range") +
  theme_minimal()
```

#### NFC
```{r, echo=FALSE, message=FALSE}
# Plot the results

ggplot(west_nrc, 
    aes(x = sentiment)) + 
    ggtitle("West Coast Sentiment Range") +
    geom_bar() +
    theme_minimal()

```

#### Bing
```{r, echo=FALSE, message=FALSE}
# Plot the results

ggplot(west_bing, 
    aes(x = sentiment, fill=sentiment)) + 
    ggtitle("West Coast Sentiment Range") +
    geom_bar() +
    theme_minimal() +
    labs(x = 'Sentiment', y = 'Count') +
    scale_color_manual(values = c('red', 'green'))
```

### Midwest (IL) {.tabset}

```{r, echo=FALSE, message=FALSE, results=FALSE}

# Read in Illinois txt file
il <- read_lines('illinois_articles.txt')

# Convert to tibble for cleaning/analysis
il <- tibble(il)

# Data Cleaning

grep_list <- list("Length", "Highlight", "Copyright", "Load-Date", "Section", "Byline", "PM EDT", "PM EST", "AM EST", "Graphic", "www")

for (str in grep_list) {
  il <- il[!grepl(str, il$il),]
}

exact_list <- list("", " ", "Body", "Link to Image", "End of Document", "Page of ")

for (str in exact_list) {
  il <- il[!(il$il==str),]
}

#Converting to character
il$il <- as.character(il$il)
clean_il <- il
```

```{r, echo=FALSE, message=FALSE}
# Data preparation chunk

# Preparing data for analysis
il_counts <- il %>% unnest_tokens(word, il) %>%
  anti_join(stop_words) %>%
  count(word, sort=TRUE)

# il_counts
il_counts$word <- as.factor(il_counts$word)

```

#### AFINN Analysis
```{r, echo=FALSE, message=FALSE}

# Sentiment Analysis Chunk

# afinn 
il_sentiment_afinn <- il_counts %>%
  inner_join(get_sentiments("afinn"))

# sentiment range plot
ggplot(data = il_sentiment_afinn, 
       aes(x=value)
        )+
  geom_histogram()+
  ggtitle("Midwest Sentiment Range")+
  theme_bw() + 
  labs(x = 'Sentiment Value', y = 'Count', title='Midwest Sentiment Range (afinn)') +
  stat_bin(bins=19)
```

#### NRC Analysis
```{r, echo=FALSE, message=FALSE}
# nrc 
il_sentiment_nrc <- il_counts %>% 
  inner_join(get_sentiments("nrc"))

# sentiment range plot
ggplot(data = il_sentiment_nrc, 
       aes(x=sentiment)
        )+
  geom_bar()+
  ggtitle("Midwest Sentiment Range")+
  theme_bw() + 
  labs(x = 'Sentiment', y = 'Count', title='Midwest Sentiment Range') +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.95, hjust=1))
```

#### Bing Analysis
```{r, echo=FALSE, message=FALSE}
# bing
il_sentiment_bing <- il_counts %>% 
  inner_join(get_sentiments("bing"))

# sentiment range plot
ggplot(data = il_sentiment_bing, 
       aes(x=sentiment, fill=sentiment)
        )+
  geom_bar()+
  ggtitle("Midwest Sentiment Range")+
  theme_bw() + 
  labs(x = 'Sentiment', y = 'Count', title='Midwest Sentiment Range') +
  scale_color_manual(values = c('red', 'green'))

ggplot(il_sentiment_bing[1:100,], aes(label = word, size = n, color=sentiment)
       ) +
  geom_text_wordcloud() +
  theme_minimal()


```

### South (FL) {.tabset}
```{r, echo=FALSE, message=FALSE, result=FALSE}

# Read in Florida data
florida <- read_lines("FloridaDataScience.txt")

florida <- tibble(florida)

# Clean up the Florida data by excluding rows without relevant info
florida <- tail(florida, -1177)

grep_list <- list("Length", "Content Type", "Narrowed by", "News", "Highlight", "Copyright", "Load-Date", "Section", "Byline", "PM EDT", "PM EST", "AM EST", "Graphic", "www", "Location by Publication", "Client/Matter", "Search", "See image link", "All Rights Reserved", "MORE DETAILS", "Sources", "Photo")

for (str in grep_list) {
  florida <- florida[!grepl(str, florida$florida),]
}

exact_list <- list("", " ", "Body", "Link to Image", "End of Document", "Page of ")

for (str in exact_list) {
  florida <- florida[!(florida$florida==str),]
}

florida$florida <- as.character(florida$florida)

clean_fl <- florida
```


``` {r, echo=FALSE, message=FALSE, result=FALSE}
florida <- florida %>%
  unnest_tokens(word, florida)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)

# Sentiment Analysis

florida_afinn <- florida %>%
  inner_join(get_sentiments("afinn"))

florida_nrc <- florida %>%
  inner_join(get_sentiments("nrc"))

florida_bing <- florida %>%
  inner_join(get_sentiments("bing"))

```

#### AFINN Analysis
```{r, echo=FALSE, message=FALSE}
ggplot(data = florida_afinn, 
       aes(x=value)) +
  geom_histogram() +
  ggtitle("South Sentiment Range") +
  theme_minimal()

```

#### NRC Analysis
```{r, echo=FALSE, message=FALSE}

ggplot(florida_nrc, 
    aes(x = sentiment)) + 
    ggtitle("South Sentiment Range") +
    geom_bar() +
    theme_minimal()


```

#### Bing Analysis
```{r, echo=FALSE, message=FALSE}
ggplot(florida_bing, 
    aes(x = sentiment, fill=sentiment)) + 
    ggtitle("South Sentiment Range") +
    geom_bar() +
    theme_minimal() +
    labs(x = 'Sentiment', y = 'Count') +
    scale_color_manual(values = c('red', 'green'))
```


### Mid-Atlantic (D.C.) {.tabset}
```{r, echo=FALSE, message=FALSE}
dc <- read_lines("DCDataScience.txt")

dc <- tibble(dc)

dc$dc <- as.character(dc$dc)

dc <- tail(dc, -2257)

grep_list <- list("Length", "Content Type", "Narrowed by", "News", "Highlight", "Copyright", "Load-Date", "Section", "Byline", "PM EDT", "PM EST", "AM EST", "Graphic", "www", "Location by Publication", "Client/Matter", "Search", "See image link", "All Rights Reserved", "MORE DETAILS", "Sources", "Photo")

for (str in grep_list) {
  dc <- dc[!grepl(str, dc$dc),]
}

exact_list <- list("", " ", "Body", "Link to Image", "End of Document", "Page of ")

for (str in exact_list) {
  dc <- dc[!(dc$dc==str),]
}

clean_dc <- dc

```


```{r, echo=FALSE, message=FALSE}
# Sentiment Anaylsis Section for DC
dc <- dc %>%
  unnest_tokens(word, dc)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)

dc_afinn <- dc %>%
  inner_join(get_sentiments("afinn"))

dc_nrc <- dc %>%
  inner_join(get_sentiments("nrc"))

dc_bing <- dc %>%
  inner_join(get_sentiments("bing"))

```

#### AFINN Analysis
```{r, echo=FALSE, message=FALSE}
ggplot(data = dc_afinn, 
       aes(x=value)) +
  geom_histogram() +
  ggtitle("Mid-Atlantic Sentiment Range") +
  theme_minimal()
```

#### NRC Analysis
```{r, echo=FALSE, message=FALSE}
ggplot(dc_nrc, 
    aes(x = sentiment)) + 
    ggtitle("Mid-Atlantic Sentiment Range") +
    geom_bar() +
    theme_minimal()
```

#### Bing Analysis
```{r, echo=FALSE, message=FALSE}
ggplot(dc_bing, 
    aes(x = sentiment, fill=sentiment)) + 
    ggtitle("Mid-Atlantic Sentiment Range") +
    geom_bar() +
    theme_minimal() +
    labs(x = 'Sentiment', y = 'Count') +
    scale_color_manual(values = c('red', 'green'))

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}

#tf_idf for all of the articles

data_prep <- function(x,y,z){
  i <- as_tibble(t(x))
  ii <- unite(i,"text",y:z,remove = TRUE,sep = "")
}

ny_bag <- data_prep(clean_ny,'V1','V2937')

il_bag <- data_prep(clean_il,'V1','V3913')

fl_bag <- data_prep(clean_fl,'V1','V3186')

west_bag <- data_prep(clean_west,'V1','V3108')

dc_bag <- data_prep(clean_dc,'V1','V819')

region <- c("North East","Midwest","South", "West", "Mid-Atlantic")


tf_idf_text <- tibble(region,text=t(tibble(ny_bag,il_bag,fl_bag,west_bag,dc_bag,.name_repair = "universal")))


word_count <- tf_idf_text %>%
  unnest_tokens(word, text) %>%
  count(region, word, sort = TRUE)

total_words <- word_count %>% 
  group_by(region) %>% 
  summarize(total = sum(n))

region_words <- left_join(word_count, total_words)

region_words <- region_words %>%
  bind_tf_idf(word, region, n)

```

## Comparison Plots by Word Frequency
```{r, echo=FALSE, message=FALSE, warning=FALSE}

region_words <- region_words[order(-region_words$tf_idf),]

# Graph for top words by region
region_words %>% 
  group_by(region) %>% 
  slice_max(tf_idf, n = 15) %>% 
  ungroup() %>% 
  ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill=region)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~region, ncol = 3, scales = "free") +
  labs(x = "tf-idf", y = NULL, title='Most Common Words by Region') +
  theme_minimal()
  
# Graph for sentiment by region

dc_imp_bing <- filter(region_words, region == "Mid-Atlantic", tf_idf > 5.0e-07)

dc_imp_bing <- dc_imp_bing %>%
  inner_join(get_sentiments("bing"))

fl_imp_bing <- filter(region_words, region == "South", tf_idf > 5.0e-07)

fl_imp_bing <- fl_imp_bing %>%
  inner_join(get_sentiments("bing"))

il_imp_bing <- filter(region_words, region == "Midwest", tf_idf > 5.e-07)

il_imp_bing <- il_imp_bing %>%
  inner_join(get_sentiments("bing"))

ny_imp_bing <- filter(region_words, region == "North East", tf_idf > 5.e-07)

ny_imp_bing <- ny_imp_bing %>%
  inner_join(get_sentiments("bing"))

west_imp_bing <- filter(region_words, region == "West", tf_idf > 5.e-07)

west_imp_bing <- west_imp_bing %>%
  inner_join(get_sentiments("bing"))

# bing_regions = rbind(dc_bing, florida_bing, il_sentiment_bing, ny_bing, west_bing)
# bing_regions$region = c(replicate(nrow(dc_bing), "Mid-Atlantic"), replicate(nrow(florida_bing), "South"), replicate(nrow(il_sentiment_bing), "Midwest"),
# replicate(nrow(ny_bing), "North East"),
# replicate(nrow(west_bing), "West"))

bing_regions = rbind(dc_imp_bing, fl_imp_bing, il_imp_bing, ny_imp_bing, west_imp_bing)
bing_regions$region = c(replicate(nrow(dc_imp_bing), "Mid-Atlantic"), replicate(nrow(fl_imp_bing), "South"), replicate(nrow(il_imp_bing), "Midwest"),
replicate(nrow(ny_imp_bing), "North East"),
replicate(nrow(west_imp_bing), "West"))

ggplot(bing_regions, aes(x=sentiment, fill=sentiment)) +
    geom_bar() +
    facet_wrap(~region) +
    labs(x='Sentiment (Bing)', y='Count', title='Sentiment Range (Bing) by Region') +
   theme_minimal() +
   theme(axis.text.x=element_blank())

```

