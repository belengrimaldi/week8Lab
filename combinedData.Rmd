---
title: "Word Sentiment -- Belen"
author: "Belen Gomez Grimaldi"
date: "3/28/2021"
output:
  html_document:
    toc: TRUE
    theme: journal
    toc_float: TRUE
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE, message=FALSE}
install.packages("dplyr")
library(dplyr)
install.packages("DT")
library(DT)
library(tidyverse)
library(tidytext)
library(ggwordcloud)
install.packages("gutenbergr") 
library(gutenbergr)
library(textdata)
install.packages("textreadr")
library("textreadr")
install.packages("striprtf")
library(striprtf)
save.image("tidytext.RData")

```
## Regional Articles Sentiment Analysis {.tabset}
### Northeast (New York)
```{r, echo=FALSE, message=FALSE}
# Read in the articles from the .txt file
ny <- read_lines("ny.txt")

# Clean the data and make it usable
ny <- tibble(ny)

ny <- tail(ny, -1098)

ny <- ny[!apply(ny == "", 1, all),]
ny <- ny[!(ny$ny=="Body"),]
ny <- ny[!(ny$ny=="Link to Image"),]
ny <- ny[!(ny$ny==" "),]
ny <- ny[!(ny$ny=="End of Document"),]
ny <- ny[!(ny$ny=="Page  of "),]
ny <- ny[!grepl("Length", ny$ny),]
ny <- ny[!grepl("Highlight", ny$ny),]
ny <- ny[!grepl("Copyright", ny$ny),]
ny <- ny[!grepl("Load-Date", ny$ny),]
ny <- ny[!grepl("Section", ny$ny),]
ny <- ny[!grepl("Byline", ny$ny),]
ny <- ny[!grepl("PM EDT", ny$ny),]
ny <- ny[!grepl("PM EST", ny$ny),]
ny <- ny[!grepl("AM EST", ny$ny),]
ny <- ny[!grepl("Graphic", ny$ny),]
ny <- ny[!grepl("www", ny$ny),]

# Save the cleaned data for a tf-idf analysis later
cleaned_ny <- ny
cleaned_ny$ny <- as.character(cleaned_ny$ny)

ny$ny <- as.character(ny$ny)

# Create a new table with count of individual words
ny <- ny %>%
  unnest_tokens(word, ny)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)

# Do sentiment analyses for the NE region

get_sentiments('afinn') 

get_sentiments('nrc')

get_sentiments('bing')

ny_afinn <- ny %>%
  inner_join(get_sentiments("afinn"))

ny_nrc <- ny %>%
  inner_join(get_sentiments("nrc"))

ny_bing <- ny %>%
  inner_join(get_sentiments("bing"))

# Plot the results
ggplot(data = ny_afinn, 
       aes(x=value)) +
  geom_histogram() +
  ggtitle("New York Sentiment Range (Afinn)") +
  theme_minimal()

ggplot(ny_nrc, 
    aes(x = sentiment)) + 
    ggtitle("New York Sentiment Range (Nrc)") +
    geom_bar() +
    theme_minimal()

ggplot(ny_bing, 
    aes(x = sentiment)) + 
    ggtitle("New York Sentiment Range (Bing)") +
    geom_bar() +
    theme_minimal()

set.seed(42)
ggplot(ny_afinn[1:50,], aes(label = word, size = n)) +
  geom_text_wordcloud() +
  ggtitle("New York Sentiment Range (Afinn)") +
  theme_minimal()

set.seed(42)
ggplot(ny_nrc[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  ggtitle("New York Sentiment Range (Nrc)")+
  theme_minimal()

set.seed(42)
ggplot(ny_bing[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  ggtitle("New York Sentiment Range (Bing)")+
  theme_minimal()


```


### West Coast (California and Oregon)
```{r, echo=FALSE, message=FALSE}
west <- read_lines("west.txt")


west <- tibble(west)

# View(ny)
west <- tail(west, -800)

west <- west[!apply(west == "", 1, all),]
west <- west[!(west$west=="Body"),]
west <- west[!(west$west=="Link to Image"),]
west <- west[!(west$west==" "),]
west <- west[!(west$west=="  "),]
west <- west[!(west$west=="   "),]
west <- west[!(west$west=="    "),]
west <- west[!(west$west=="End of Document"),]
west <- west[!(west$west=="Final Edition"),]
west <- west[!(west$west=="Page  of "),]
west <- west[!grepl("Length", west$west),]
west <- west[!grepl("Highlight", west$west),]
west <- west[!grepl("Copyright", west$west),]
west <- west[!grepl("Load-Date", west$west),]
west <- west[!grepl("Section", west$west),]
west <- west[!grepl("Byline", west$west),]
west <- west[!grepl("PM PST", west$west),]
west <- west[!grepl("AM PST", west$west),]
west <- west[!grepl("Graphic", west$west),]

west$west <- as.character(west$west)

clean_west <- west

west <- west %>%
  unnest_tokens(word, west)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)
# View(west)

get_sentiments('afinn') 

get_sentiments('nrc')

get_sentiments('bing')

west_afinn <- west %>%
  inner_join(get_sentiments("afinn"))
# View(ny_afinn)

west_nrc <- west %>%
  inner_join(get_sentiments("nrc"))
# View(ny_nrc)

west_bing <- west %>%
  inner_join(get_sentiments("bing"))
# View(ny_bing)

ggplot(data = west_afinn, 
       aes(x=value)) +
  geom_histogram() +
  ggtitle("West Coast Sentiment Range (Afinn)") +
  theme_minimal()

ggplot(west_nrc, 
    aes(x = sentiment)) + 
    ggtitle("West Coast Sentiment Range (Nrc)") +
    geom_bar() +
    theme_minimal()

ggplot(west_bing, 
    aes(x = sentiment)) + 
    ggtitle("West Coast Sentiment Range (Bing)") +
    geom_bar() +
    theme_minimal()

set.seed(42)
ggplot(west_afinn[1:50,], aes(label = word, size = n)) +
  geom_text_wordcloud() +
  ggtitle("West Coast Sentiment Range (Afinn)") +
  theme_minimal()

set.seed(42)
ggplot(west_nrc[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  ggtitle("West Coast Sentiment Range (Nrc)")+
  theme_minimal()

set.seed(42)
ggplot(west_bing[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  ggtitle("West Coast Sentiment Range (Bing)")+
  theme_minimal()



```

### Midwest 

```{r}

# Read in Illinois txt file
il <- read_lines('illinois_articles.txt')
il

# Convert to tibble for cleaning/analysis
il <- tibble(il)

# Data Cleaning
# Function to clean all txt files
clean_article <- function(x){
  clean_txt <- x[!apply(x == "", 1, all),] %>%   x[!(x$x=="Body"),] %>%
x[!(x$x=="Link to Image"),] %>%
x[!(x$x==" "),] %>%
xl[!(x$x=="End of Document"),] %>%
x[!(x$x=="Page  of "),] %>%
x[!grepl("Length", x$x),] %>%
x[!grepl("Highlight", x$x),] %>%
x[!grepl("Copyright", x$x),] %>%
x[!grepl("Load-Date", x$x),] %>%
x[!grepl("Section", x$x),] %>%
x[!grepl("Byline", x$x),] %>%
x[!grepl("PM EDT", x$x),] %>%
x[!grepl("PM EST", x$x),] %>%
x[!grepl("AM EST", x$x),] %>%
x[!grepl("Graphic", x$x),] %>%
x[!grepl("www", x$x),]
}
clean_il <- clean_article(il)

il <- il[!apply(il == "", 1, all),]
il <- il[!(il$il=="Body"),]
il <- il[!(il$il=="Link to Image"),]
il <- il[!(il$il==" "),]
il <- il[!(il$il=="End of Document"),]
il <- il[!(il$il=="Page  of "),]
il <- il[!grepl("Length", il$il),]
il <- il[!grepl("Highlight", il$il),]
il <- il[!grepl("Copyright", il$il),]
il <- il[!grepl("Load-Date", il$il),]
il <- il[!grepl("Section", il$il),]
il <- il[!grepl("Byline", il$il),]
il <- il[!grepl("PM EDT", il$il),]
il <- il[!grepl("PM EST", il$il),]
il <- il[!grepl("AM EST", il$il),]
il <- il[!grepl("Graphic", il$il),]
il <- il[!grepl("www", il$il),]

clean_il <- il
```

## Data Preparation
```{r}
#Converting to character
clean_il$il <- as.character(clean_il$il)
il$il <- as.character(il$il )

# Preparing data for analysis
#Function
prepared_data <- function(x){
  x %>% unnest_tokens(word, x) %>%
    anti_join(stop_words) %>%
    count(word, sort=TRUE)
}
prepared_data(il)

il_counts <- il %>% unnest_tokens(word, il) %>%
  anti_join(stop_words) %>%
  count(word, sort=TRUE)

il_counts
il_counts$word <- as.factor(il_counts$word)

#Graph 
ggplot(
  data = il_counts,
  aes(x = fct_reorder(word,n),
      y = n)
  ) + 
  geom_col() + 
  coord_flip()+
  theme_light()

```

## Sentiment Analysis
```{r}

# afinn 
get_sentiments('afinn')
il_sentiment_afinn <- il_counts %>%
  inner_join(get_sentiments("afinn"))
# sentiment range plot
ggplot(data = il_sentiment_afinn, 
       aes(x=value)
        )+
  geom_histogram()+
  ggtitle("Illinois Sentiment Range")+
  theme_bw() + 
  labs(x = 'Sentiment Value', y = 'Count', title='Illinois Sentiment Range (afinn)') +
  stat_bin(bins=19)
# word cloud
ggplot(il_sentiment_afinn[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  theme_bw()


# nrc 
get_sentiments('nrc')
il_sentiment_nrc <- il_counts %>% 
  inner_join(get_sentiments("nrc"))
# sentiment range plot
ggplot(data = il_sentiment_nrc, 
       aes(x=sentiment)
        )+
  geom_bar()+
  ggtitle("Illinois Sentiment Range")+
  theme_bw() + 
  labs(x = 'Sentiment', y = 'Count', title='Illinois Sentiment Range (nrc)') +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.95, hjust=1))
# word cloud
set.seed(8)
ggplot(il_sentiment_nrc[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  theme_bw()

# bing
get_sentiments('bing')
il_sentiment_bing <- il_counts %>% 
  inner_join(get_sentiments("bing"))
# sentiment range plot
ggplot(data = il_sentiment_bing, 
       aes(x=sentiment, fill=sentiment)
        )+
  geom_bar()+
  ggtitle("Illinois Sentiment Range")+
  theme_bw() + 
  labs(x = 'Sentiment', y = 'Count', title='Illinois Sentiment Range (bing)') +
  scale_color_manual(values = c('red', 'green'))

# word cloud
ggplot(il_sentiment_bing[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  theme_bw()



```

### South (Florida)
```{r}

florida <- read_lines("FloridaDataScience.txt")

florida <- tibble(florida)
View(florida)

florida$florida <- as.character(florida$florida)

clean_fl <- florida

View(florida)

florida <- florida %>%
  unnest_tokens(word, florida)%>%
  anti_join(stop_words)%>% 
  count(word, sort=TRUE)

View(florida)

get_sentiments('afinn') 

get_sentiments('nrc')

get_sentiments('bing')

florida_afinn <- florida %>%
  inner_join(get_sentiments("afinn"))
View(florida_afinn)

florida_nrc <- florida %>%
  inner_join(get_sentiments("nrc"))
View(florida_nrc)

florida_bing <- florida %>%
  inner_join(get_sentiments("bing"))
View(florida_bing)

table(florida_afinn$value)
table(florida_nrc$sentiment)
table(florida_bing$sentiment)

ggplot(data = florida_afinn, 
       aes(x=value)) +
  geom_histogram() +
  ggtitle("Florida Sentiment Range (Afinn)") +
  theme_minimal()

ggplot(florida_nrc, 
    aes(x = sentiment)) + 
    ggtitle("Florida Sentiment Range (Nrc)") +
    geom_bar() +
    theme_minimal()

ggplot(florida_bing, 
    aes(x = sentiment)) + 
    ggtitle("Florida Sentiment Range (Bing)") +
    geom_bar() +
    theme_minimal()

set.seed(42)
ggplot(florida_afinn[1:50,], aes(label = word, size = n)) +
  geom_text_wordcloud() +
  ggtitle("Florida Sentiment Range (Afinn)") +
  theme_minimal()

set.seed(42)
ggplot(florida_nrc[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  ggtitle("Florida Sentiment Range (Nrc)")+
  theme_minimal()

set.seed(42)
ggplot(florida_bing[1:50,], aes(label = word, size = n)
       ) +
  geom_text_wordcloud() +
  ggtitle("Florida Sentiment Range (Bing)")+
  theme_minimal()
```

## Comparing Relative Word Frequencies

```{r, echo=FALSE, message=FALSE}
cleaned_ny
clean_il
clean_fl
clean_west

data_prep <- function(x,y,z){
  i <- as_tibble(t(x))
  ii <- unite(i,"text",y:z,remove = TRUE,sep = "")
}

ny_bag <- data_prep(cleaned_ny,'V1','V2837')

il_bag <- data_prep(clean_il,'V1','V3913')

fl_bag <- data_prep(clean_fl,'V1','V6372')

west_bag <- data_prep(clean_west,'V1','V3038')

region <- c("North East","Midwest","South", "West")


tf_idf_text <- tibble(region,text=t(tibble(ny_bag,il_bag,fl_bag,west_bag,.name_repair = "universal")))

class(tf_idf_text)

word_count <- tf_idf_text %>%
  unnest_tokens(word, text) %>%
  count(region, word, sort = TRUE)

total_words <- word_count %>% 
  group_by(region) %>% 
  summarize(total = sum(n))

region_words <- left_join(word_count, total_words)

region_words <- region_words %>%
  bind_tf_idf(word, region, n)

```
